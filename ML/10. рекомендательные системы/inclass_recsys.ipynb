{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inclass_recsys.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EpMBaftzEmuQ"},"source":["Разберем простые рекомендательные системы. Для этого возьмем датасет с рейтингами аниме и попробуем посоветовать пользователям сайта, что же им еще можно посмотеть.\n","\n","Импортируем необходимые библиотеки."]},{"cell_type":"markdown","metadata":{"id":"HIIOzCfhEmuR"},"source":["## Обработка данных"]},{"cell_type":"code","metadata":{"id":"QiZjgmztEmuS"},"source":["import pandas as pd\n","import numpy as np\n","import scipy.sparse as scp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dl0Bkr6MEmuV"},"source":["Загрузим датасет с аниме, их названием, рейтингами"]},{"cell_type":"code","metadata":{"id":"1udY-k8UEmuV"},"source":["anime = pd.read_csv('./anime.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1mEQQoeEmuY"},"source":["Рассмотрим только те аниме, которые входят в категорию TV"]},{"cell_type":"code","metadata":{"id":"w1LqXmF3EmuZ"},"source":["anime = anime.loc[anime.type == 'TV']\n","anime.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnmorkxHEmue"},"source":["Так же загрузим датасет с рейтигами, который пользователи ставили определенным аниме"]},{"cell_type":"code","metadata":{"id":"bun7xthnEmue"},"source":["rating = pd.read_csv('./rating.csv')\n","rating.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54nnmtoCEmuh"},"source":["Как видим, оба датасета имеют поле `anime_id`. Можем по этому полю соединить обе таблицы. Получим таблицу `merged`, в которой хранится, какой пользователь поставил какую оценку конкретному аниме.\n","\n","Заметьте, что в обоих таблицах есть поле `rating`, поэтому при соединении таблиц изменим название этого поля в таблице `rating` на `rating_user`, добавив суффикс `_user`"]},{"cell_type":"code","metadata":{"id":"DoHpLVmwEmui","scrolled":true},"source":["merged = rating.merge(anime, left_on='anime_id', right_on='anime_id', suffixes=['_user', ''])\n","merged.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vs8KNpV4Emul"},"source":["Нам не нужно знать все о получившийся таблице. Главное знать id пользователя, название аниме и саму оценку. Оставим только нужные нам поля."]},{"cell_type":"code","metadata":{"id":"4AYTUR9aEmum"},"source":["merged = merged[['user_id', 'name', 'rating_user']]\n","merged.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvKAa3PhEmup"},"source":["Изменим навзание поля `rating_user` на более удобное для понимания: `user_rating`"]},{"cell_type":"code","metadata":{"id":"5iDZrwviEmuq"},"source":["merged.rename(columns={'rating_user': 'user_rating'}, inplace=True)\n","merged.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L1YF07OcEmut"},"source":["Рейтинг `-1` значит, что пользователь посмотел аниме, но не поставил ему оценку. Так как нас интересуют только рейтинги, можно выкинуть все `-1`"]},{"cell_type":"code","metadata":{"id":"1UCYsU1AEmuv","scrolled":true},"source":["merged = merged.loc[merged.user_rating != -1]\n","merged.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93OP_3N0Emuz"},"source":["Выкинем часть датасета, чтобы избежать проблем с вычислениями."]},{"cell_type":"code","metadata":{"id":"s7a0E1eXEmuz","scrolled":true},"source":["merged = merged.loc[merged.user_id <= 10000]\n","merged.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LbIApg1NEmu2"},"source":["Теперь разобьем данные на train и test части. Это не самый лучший способ разбить датасет на части, но сейчас для простоты используем его."]},{"cell_type":"code","metadata":{"id":"77Y0TQyPEmu3"},"source":["from sklearn.model_selection import train_test_split\n","\n","random_state = 314159"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STSViHjJEmu6"},"source":["train_data, dev_data = train_test_split(merged, test_size=0.1, random_state=random_state)\n","train_data.sort_index(inplace=True)\n","dev_data.sort_index(inplace=True)\n","train_data.shape, dev_data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmytF9buEmu8"},"source":["Train часть датасета"]},{"cell_type":"code","metadata":{"id":"L-Hmiy1mEmu9"},"source":["train_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gX7vt8inEmvA"},"source":["Test часть датасета"]},{"cell_type":"code","metadata":{"id":"ku2P3Y3SEmvB"},"source":["dev_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyUQb074EmvE"},"source":["if len(merged.user_id.unique()) == merged.user_id.max():\n","    print('Количество уникальных пользователей совпадает с максимальным id пользователя')\n","else:\n","    print('Количество уникальных пользователей НЕ совпадает с максимальным id пользователя')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VE-3sTZZEmvH"},"source":["merged.user_id.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jUFAZPRUEmvL"},"source":["Как можно видеть, количество уникальных пользователей не совпадает с максимальным id пользователя, а это значит, что id пользователей сдвинуты. Так, например, отсутствуют пользователи, с `id` 0, 1, 2  и 4.\n","\n","В дальнейшем нам надо будет работать с матрицей рейтингов, где 0-ая строка соответствует пользователю с `id` 3, 1-ая строка -- пользователю с `id` 5 и так далее. Поэтому для удобства создадим словарь, который переводит настоящий id пользователя в удобный нам. Сразу же сделаем словарь, который делает обратное преобразование."]},{"cell_type":"code","metadata":{"id":"zmQ-NCy_EmvL"},"source":["user_to_idx = {user_id : idx for idx, user_id in enumerate(merged.user_id.unique())}\n","idx_to_user = {i: user for user, i in user_to_idx.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8chWMBtEmvN"},"source":["assert 9387 == len(user_to_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a5o2wDGzEmvQ"},"source":["Как видно, первый словать перевел пользователя с id 5 в пользователя с id 1. То, что нам и нужно было"]},{"cell_type":"code","metadata":{"id":"arRJDnPgEmvR","scrolled":true},"source":["user_to_idx[5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lfpyEK7cEmvU"},"source":["Обратное преобразование так же работает"]},{"cell_type":"code","metadata":{"id":"HZxi2BHqEmvV"},"source":["idx_to_user[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76mHufLxEmvX"},"source":["Так же необходимо сопоставить именам аниме индексацию "]},{"cell_type":"code","metadata":{"id":"OGcn_5m0EmvX"},"source":["anime_to_idx = {anime_name : idx for idx, anime_name in enumerate(merged.name.unique())}\n","idx_to_anime = {i: anime_name for anime_name, i in anime_to_idx.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFCsp1PlEmvZ"},"source":["assert 2708 == len(anime_to_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QAXyZbkzEmvd"},"source":["Так можно видеть, что 0-ому столбцу соответсвует Naruto"]},{"cell_type":"code","metadata":{"id":"Ks_kpPuNEmvd"},"source":["idx_to_anime[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEbUf_QCEmvg"},"source":["Преобразуем train часть датасета с помощью преобразований, описанных выше."]},{"cell_type":"code","metadata":{"id":"1BKn-vqOEmvh"},"source":["data = train_data.copy()\n","data['user_id'] = data['user_id'].apply(lambda x: user_to_idx[x])\n","data['name'] = data['name'].apply(lambda x: anime_to_idx[x])\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4mintwn2Emvk"},"source":["## Создание матрицы рейтингов"]},{"cell_type":"markdown","metadata":{"id":"h-niRCxBEmvl"},"source":["Теперь мы готовы для того, чтобы составить саму матрицу рейтингов. Если мы будем хранить все значения, то есть не только сами оценки пользователей, но так же и нули, говорящие о том, что оценки не было, то в итоге такая матрица займет слишком много места. Вместо этого используют размереженные матрицы.\n","\n","Конкретно сейчас, будем работать с матрицей типа `coo_matrix`. Для того, чтобы созадть такую матрицу, достаточно знать координаты каждого ненулевого элемента. В нашей рекомендательной системе координатами являются id пользователей и id аниме.\n","\n","<img src='http://cdncontribute.geeksforgeeks.org/wp-content/uploads/Sparse-Matrix-Array-Representation1.png'>"]},{"cell_type":"markdown","metadata":{"id":"z_mEe4fZEmvl"},"source":["Так же нужно указать размеры создаваемой матрицы. У нас есть пользователи, которые не поставили ни одной оценки, а так же есть аниме, которым не ставили ни одной оценки. Чтобы случайно не выкинуть таких пользователей и такие аниме, зафиксируем размеры матрицы рейтингов."]},{"cell_type":"code","metadata":{"id":"NFrchea-Emvm"},"source":["def get_sparse(data):\n","    return scp.coo_matrix(\n","        (\n","            data['user_rating'],  # оценки пользователей\n","            (data['user_id'], data['name'])  # id пользователей и id аниме, для которых известны оценки\n","        ), \n","        shape=(len(user_to_idx), len(anime_to_idx))  # размеры матрицы рейтингов\n","    ).tocsr()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDcgCs1SEmvo"},"source":["train_sp = get_sparse(data)\n","train_sp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhSPssRJEmvq"},"source":["Можем перевести получившуюся `sparce` матрицу обратно к `dense` формату. Видно, что все проставленные оценки расположились так, что если оценка `r` стоит в `i` строке и `j` столбце, то значит пользователь с id `i` поставил аниме с id `j` оценку `r`. Все остальные поля заполнены нулями."]},{"cell_type":"code","metadata":{"id":"bqfppOjYEmvs"},"source":["train_dense = train_sp.todense().A\n","train_dense"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lviFJgWYEmvv"},"source":["Еще раз повторюсь: правильно работать с матрицей рейтингов, которая при этом является разреженной матрицей. Но так как мы пока что учимся, далее будем использовать знакомый нам тип: `dense`."]},{"cell_type":"markdown","metadata":{"id":"PiNRjbzZEmvw"},"source":["## Baseline prediction"]},{"cell_type":"markdown","metadata":{"id":"Tm-6xoHBEmvx"},"source":["Для начала попробуем предсказывать рейтинги пользователей простым способом. Найдем средний рейтинг для всех пользователей и всех аниме. Для этого просуммируем все проставленные рейтинги и поделим на их количество.\n","$$\n","\\begin{align*}\n","\\mu=&\\frac{1}{n}\\sum_{u,i}r_{ui}\n","\\end{align*}\n","$$\n","Уже можно было бы сказать, что неизвестная нам оценка, которую поставит некий пользователь аниме, равна среднему. Но мы пойдем чуть дальше. Будем учитывать предвзятость пользователей и переоценку/недооценку аниме. Как пример, некоторые пользователи ставят в основном 10, а 9 для них - ужасный фильм, для некоторых пользователей наблюдается обратная ситуация: даже 5 для них - это шедевр кинематографа. С аниме такая же ситуация.\n","\n","Сначала разберемся с пользователями. Для того, чтобы вычислить \"сдвиг\" в оценках пользователя $u$ относительно средней оценки $\\mu$, достаточно вычесть из всех его оценок $r_{ui}$ среднюю оценку $\\mu$, просуммировать результат и поделить на количество оценкок $|I_u|$, который этот пользователь поставил. Так как не все пользователи ставили оценки, то введем параметр $\\alpha$, чтобы избежать деления на 0. $\\alpha$ можно взять равным 1, но так как $\\alpha$ еще является и коэффициентом сглаживания, то возьмем его равным $25$.\n","$$\n","\\begin{align*}\n","b_u=&\\frac{1}{|I_u|+\\alpha}\\sum_{i\\in{}I_u}(r_{ui} - \\mu), \\space\\space\\space \\alpha=25\n","\\end{align*}\n","$$\n","Аналогично вычислим \"сдвиг\" в оценивании аниме $i$, но на этот раз учтем еще и найденные ранее сдвиги в оценках пользователей. Так же введем коэффициент сглаживания $\\beta$ и примем его равным коэффициенту $\\alpha$.\n","$$\n","\\begin{align*}\n","b_i=&\\frac{1}{|U_i|+\\beta}\\sum_{u^\\prime\\in{}U_i}(r_{u^\\prime{}i} - b_{u^\\prime} - \\mu), \\space\\space\\space \\beta=25\n","\\end{align*}\n","$$\n","Итоговое предсказание оценки $r_{ui}$ пользователя $u$ аниме $i$\n","$$\n","\\begin{align*}\n","\\hat{r}_{ui}=&\\mu+b_u+b_i\n","\\end{align*}\n","$$"]},{"cell_type":"code","metadata":{"id":"NsWY-Zr8Emvy"},"source":["alpha = beta = 25"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEGVnmj3Emvz"},"source":["Так как при вычислении среднего рейтинга нам надо учитывать только известные оценки, то используем формат `masked_array`, который \"скроет\" все нули. Такой формат представляет из себя 2 поля: `data` и `mask`. В `data` хранятся все необходимые данные (в нашем случае матрица рейтингов), а в `mask` указывается, какие значения из `data` учитываются: True - значение не учитывается, False - учитывается."]},{"cell_type":"code","metadata":{"id":"4FJfPg0-Emv0"},"source":["import numpy.ma as ma"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jt23Sl0aEmv2"},"source":["train_dense_masked = ma.masked_array(train_dense, mask=train_dense == 0, fill_value=0)\n","train_dense_masked"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_048J-i0Emv5"},"source":["Вычислим среднюю оценку. Довольно высокая :)"]},{"cell_type":"code","metadata":{"id":"IAcXg7OEEmv6"},"source":["mu = train_dense_masked.mean()\n","mu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9dtkUXeEmv8"},"source":["С учетом средней оценки вычислим \"сдвиг\" в оценке для каждого пользователя по формуле, описанной выше.\n","\n","Уже видно, что, например, второй пользователь в среднем ставит оценку на 3 балла меньше, чем средняя оценка всех пользователей. То есть там, где обычный пользователь поставил бы 8, он поставит 5. Именно из-за таких пользователей и следует делать поправку на предвзятость."]},{"cell_type":"code","metadata":{"id":"H0qoubucEmv8"},"source":["bu = (train_dense_masked - mu).sum(1)/((~train_dense_masked.mask).sum(1) + alpha)\n","bu.fill_value = 0\n","assert bu.shape == (len(user_to_idx), )\n","bu"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"eK0CDJLLEmwB"},"source":["Так же вычислим \"сдвиг\" для аниме. Как вы помните, выше выяснили, что для нашей индексации аниме с индексом 0 - это \"Наруто\". Как видим, нулевой элемент вектора сдвига для аниме равен $\\approx{-0.09}$, то есть это насколько средняя оценка \"Наруто\" на 0.09 меньше средней оценки $\\mu$."]},{"cell_type":"code","metadata":{"id":"B5B5P6-dEmwC"},"source":["bi = (train_dense_masked - bu[..., None] - mu).sum(0)/((~train_dense_masked.mask).sum(0) + beta)\n","bi.fill_value = 0\n","assert bi.shape == (len(anime_to_idx), )\n","bi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w5WpqY-_EmwL"},"source":["В итоге объединим \"сдвиги\" пользователей и \"сдвиги\" аниме в единую матрицу. Тогда значение $b_{ui}$, находящееся на пересечении строки $u$ и столбца $i$, будет равно \"сдвигу\" оценивания аниме $i$ пользователем $u$ относительно средней оценки $\\mu$."]},{"cell_type":"code","metadata":{"id":"KdDVyR-7EmwM"},"source":["B = bu[..., None] + bi  # or np.outer(bu, bi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mMue6TgEmwP"},"source":["Сложим среднюю оценку $\\mu$ и все известные нам сдвиги $B$ в соответствии с формулой, описанной выше, и получим нашу простую рекомендательную систему. Значение $r_{ui}$, находящееся на пересечении строки $u$ и столбца $i$ матрицы baseline_predictions, оценка, которую поставит пользователь $u$ аниме $i$."]},{"cell_type":"code","metadata":{"id":"SlUlu-KLEmwP"},"source":["baseline_predictions = mu + B\n","baseline_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XdzcZt-NEmwR"},"source":["Посмотрим, насколько хорошо наша модель справляется. Для этого сгруппируем все оценки пользователей в train и test датасетах"]},{"cell_type":"code","metadata":{"id":"kKDpZPjEEmwS"},"source":["train_grby_user = train_data.groupby('user_id')\n","dev_grby_user = dev_data.groupby('user_id')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c_BKKOF9EmwT"},"source":["Выведем, какие оценки нам известны для пользователя с id 18"]},{"cell_type":"code","metadata":{"id":"PHEPyeIpEmwU"},"source":["# 16, 18, 19, 20\n","user = 18\n","train_grby_user.get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhBreoSwEmwW"},"source":["Так же посмотрим, что он еще посмотрел и поставил оценки, но нам о них ничего не было известно на момент построения baseline prediction, так как они в тестовой выборке"]},{"cell_type":"code","metadata":{"id":"p6m8zCvqEmwX"},"source":["dev_grby_user.get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvC90_9rEmwa"},"source":["Напишем небольшую функцию, которая вернет `top_k` аниме, которые должны понравиться пользователю с id `user`, а так же их прогнозируемые оценки"]},{"cell_type":"code","metadata":{"id":"r87JRU4OEmwb"},"source":["def line_on_baseline(user, top_k=10):\n","    # отсортируем все рейтинги по убыванию\n","    ratings = baseline_predictions[user_to_idx[user]]\n","        \n","    anime_to_line_on = []\n","    for anime_idx in np.argsort(ratings)[::-1]:\n","        # пропустим аниме, которые пользователь уже смотрел\n","        if ma.is_masked(ratings[anime_idx]):\n","            continue\n","\n","        # если нашли аниме, которое пользователь не смотрел, то добавим его в список\n","        if idx_to_anime[anime_idx] not in train_grby_user.get_group(user).name.values:\n","            anime_to_line_on.append((idx_to_anime[anime_idx], ratings[anime_idx]))\n","\n","        # если список аниме, которые понравятся, уже содержит top_k фильмов, то прекратим поиск\n","        if len(anime_to_line_on) == top_k:\n","            break\n","            \n","    return anime_to_line_on"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYp1k3faEmwc"},"source":["dev_grby_user.get_group(16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0DXWDayEmwe","scrolled":false},"source":["line_on_baseline(16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYnfhd3vEmwg"},"source":["dev_grby_user.get_group(18)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRM5j_9lEmwi"},"source":["line_on_baseline(18)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MNLb-Zn2Emwk"},"source":["## Использование схожести пользователей"]},{"cell_type":"markdown","metadata":{"id":"TPcqylx_Emwl"},"source":["До этого мы считали рейтинг пользователей отталкиваясь от среднего рейтинга всех пользователей. Поэтому даже если пользователю $u$ нравится только жанр ужасы, мы при вычислении его оценок так же учитывали оценки тех пользователей, кто больше любит жанр комедии, что неправильно. Поэтому модефицируем наш простой алгоритм: во-первых, будем учитывать только $N$ похожих пользователей (множество $U_{sim}$); во-вторых, каждый рейтинг будем учитывать с весом равным схожести пользователей.\n","$$\n","\\hat{r}_{ui}=\\frac{\\sum_{u^\\prime \\in U_{sim}}sim(u,u^\\prime)r_{u^\\prime{}i}}{\\sum_{u^\\prime \\in U_{sim}}|sim(u,u^\\prime)|}\n","$$\n","Немного улучшим алгоритм, используя уже знакомый вам подход: усредним не оценки похожих пользователей, а их \"сдвиги\" в оценках, и добавим это к средней оценке пользователя $u$.\n","$$\n","\\hat{r}_{ui}=\\bar{r}_u+\\frac{\\sum_{u^\\prime}sim(u,u^\\prime)(r_{u^\\prime{}i}-\\bar{r}_{u^\\prime})}{\\sum_{u^\\prime}|sim(u,u^\\prime)|}\n","$$\n","Здесь $\\bar{r}_u$ - средний рейтинг пользователя $u$.\n","\n","Используем косинусную близость:\n","$$\n","{\\displaystyle {\\text{similarity}}=\\cos(\\theta )={\\mathbf {A} \\cdot \\mathbf {B}  \\over \\|\\mathbf {A} \\|\\|\\mathbf {B} \\|}={\\frac {\\sum \\limits _{i=1}^{n}{A_{i}B_{i}}}{{\\sqrt {\\sum \\limits _{i=1}^{n}{A_{i}^{2}}}}{\\sqrt {\\sum \\limits _{i=1}^{n}{B_{i}^{2}}}}}},}\n","$$\n","Для облегчения задачи нормализуем вектора рейтингов для каждого пользователя.\n","$$\n","R^\\prime=r_{ui}-\\mu-b_u-b_i.\n","$$"]},{"cell_type":"code","metadata":{"id":"HRyoRvG7Emwl"},"source":["train_norm = train_dense_masked - baseline_predictions\n","train_norm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QJDAOhd1Emwo"},"source":["Вычислим косинусную близость между пользователями и между аниме. Стоит помнить, что функция `cosine_similarity` вычисляет косинусную близость между всеми строками данной матрицы. В `train_norm` в строках лежат данные о пользователях, поэтому `cosine_similarity(train_norm)` даст нам матрицу косинусной близости между всеми пользователями. Для того, чтобы получить в строчках инфорацию об аниме, транспонируем матрицу `train_norm`: `train_norm.T`, и вызовем функцию для неё: `cosine_similarity(train_norm.T)`."]},{"cell_type":"code","metadata":{"id":"n4KRN6UgEmwp"},"source":["from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GG8-CZ85Emwr"},"source":["user_similarities = cosine_similarity(train_norm)\n","item_similarities = cosine_similarity(train_norm.T)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgpXinzQEmws"},"source":["assert user_similarities.shape == (len(user_to_idx), len(user_to_idx))\n","assert item_similarities.shape == (len(anime_to_idx), len(anime_to_idx))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-HYOXB9Emwu"},"source":["Напишем функцию, которая возвращает `top_k` аниме, похожих на `anime_name`. Заметим, что они будут похожи не по жанру, а по аудитории."]},{"cell_type":"code","metadata":{"id":"YhC0OdgJEmwu"},"source":["def top_anime(anime_name, top_k=10):\n","    # найдем индекс аниме\n","    anime_idx = anime_to_idx[anime_name]\n","    \n","    print('Top {} to: {}'.format(top_k, anime_name))\n","    # выведем top_k похожих аниме, при этом стоит помнить, что \"самое похожее\" аниме на anime_name и есть само anime_name\n","    for i, j in enumerate(np.argsort(item_similarities[anime_idx])[::-1][1:top_k + 1]):\n","        print('#{}: {}'.format(i + 1, idx_to_anime[j]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlAo9pc5Emwv"},"source":["top_anime('Naruto')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUbuhzvtEmwy","scrolled":true},"source":["top_anime('Bleach')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1FNETPxXEmwz"},"source":["top_anime('Cowboy Bebop')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySKWsscGEmw1"},"source":["top_anime('Samurai Champloo')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhCg-L0_Emw3"},"source":["train_norm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Biownq7IEmw5"},"source":["Использую матрицу близости пользователей найдем самых близких $N$ и по ним определим рейтинг."]},{"cell_type":"code","metadata":{"id":"VSHMKxHBEmw6"},"source":["def predicted_rating(item_name, user_id, N=50):\n","    item_idx = anime_to_idx[item_name]\n","    user_idx = user_to_idx[user_id]\n","    \n","    sim_users = np.argsort(user_similarities[user_idx])[::-1][1:N + 1]\n","    user_values = user_similarities[user_idx][sim_users]\n","    \n","    b = train_norm[sim_users].mean(1)\n","    \n","    return train_norm[user_idx].mean() + ((train_norm[sim_users, item_idx] - b)*user_values).sum()/np.abs(user_values).sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNilv98UEmw7"},"source":["from tqdm import tqdm\n","\n","def line_on_user_user(user, top_k=10, N=50):\n","    ratings = []\n","    for anime in tqdm(anime_to_idx):\n","        ratings.append(predicted_rating(anime, user, N))\n","        \n","    anime_to_line_on = []\n","    for anime_idx in np.argsort(ratings)[::-1]:\n","        if len(anime_to_line_on) == top_k:\n","            break\n","        if ma.is_masked(ratings[anime_idx]):\n","            continue\n","        if idx_to_anime[anime_idx] not in train_grby_user.get_group(user).name.values:\n","            anime_to_line_on.append((idx_to_anime[anime_idx], ratings[anime_idx]))\n","            \n","    return anime_to_line_on"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoK8PkJpEmw8"},"source":["user = 18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArLO1ukXEmw-"},"source":["train_grby_user.get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tiEbuj8kEmw_","scrolled":true},"source":["dev_grby_user.get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IhBLzgsEmxB"},"source":["top_k = 10\n","line_on_user_user(user, top_k=top_k)  # with N=1000 ok!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HSetCLCkEmxC"},"source":["## Латентные признаки: SVD"]},{"cell_type":"markdown","metadata":{"id":"hnpPukqKEmxD"},"source":["Как было сказано на лекции, мы можем использовать для предсказания знания о пользователе, которые он сам сообщил. Это может быть пол, возраст, любимые фильмы и тд. Но что делать, если пользователь ничего не указал? В этом случае нам могут помочь латентные (скрытые) признаки. Рассмотрим пример.\n","<table>\n","<tr>\n","<td></td>\n","<td>Титаник</td>\n","<td>Дневник памяти</td>\n","<td>Трансформеры</td>\n","<td>Youtube Rewind 2018</td>\n","<td>Форсаж</td>\n","</tr>\n","<tr>\n","<td>User 1</td>\n","<td>5</td>\n","<td>5</td>\n","<td>1</td>\n","<td>0</td>\n","<td>1</td>\n","</tr>\n","<tr>\n","<td>User 2</td>\n","<td>1</td>\n","<td>1</td>\n","<td>5</td>\n","<td>0</td>\n","<td>5</td>\n","</tr>\n","</table>\n","Видно, что User 1 предпочитает больше мелодраммы, тогда как User 2 любит больше экшн фильмы, хотя ни тот, ни другой нигде это не указали. Это и есть латентные признаки.\n","\n","Один из способов \"достать\" такие признаки - разложение (факторизация) матрицы\n","$$\n","R=UI^T,\n","$$\n","где $R\\in\\mathbb{R}^{u\\times{}i}$, $U\\in\\mathbb{R}^{u\\times{}k}$ и $I\\in\\mathbb{R}^{i\\times{}k}$, где $k$ небольшое значение. Такого разложения можно добиться, используя `SVD` разложение."]},{"cell_type":"code","metadata":{"id":"NbMUDSO6EmxD"},"source":["u, s, vt = scp.linalg.svds(scp.csr_matrix(train_norm.data), k=100)\n","u = u.dot(np.diag(s))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8U2B0-MEmxF"},"source":["def line_on_svd(user, top_k=10):\n","    ratings = []\n","    for anime in tqdm(anime_to_idx):\n","        rat = np.sum(u[user_to_idx[user]]*vt[:, anime_to_idx[anime]])\n","#         rat *= data_norm_fro\n","#         rat += bu[user_to_idx[user]]\n","#         rat += bi[anime_to_idx[anime]]\n","#         rat += mu\n","        ratings.append(rat)\n","\n","    anime_to_line_on = []\n","    for anime_idx in np.argsort(ratings)[::-1]:\n","        if ma.is_masked(ratings[anime_idx]):\n","            continue\n","        if len(anime_to_line_on) == top_k: break\n","        if idx_to_anime[anime_idx] not in train_data.groupby('user_id').get_group(user).name.values:\n","            anime_to_line_on.append((idx_to_anime[anime_idx], ratings[anime_idx]))\n","            \n","    return anime_to_line_on"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASMtuDtYEmxI"},"source":["user = 18\n","train_grby_user.get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYGauvMdEmxK"},"source":["dev_grby_user.get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Kx8CxlyEmxM","scrolled":true},"source":["line_on_svd(user, top_k=top_k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dySdc81tEmxP","scrolled":false},"source":["line_on_user_user(user, top_k=top_k)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dwS0t8ifEmxS"},"source":[" "]},{"cell_type":"markdown","metadata":{"id":"vzG0TMFYEmxS"},"source":["Попробуем использовать библиотеку [`surprise`](https://surprise.readthedocs.io/en/stable/) для SVD разложения."]},{"cell_type":"code","metadata":{"id":"cueGT9D4EmxS"},"source":["from surprise import Reader, Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7GuGzjkkEmxV"},"source":["# to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n","ratings_dict = {'itemID': list(train_data.name),\n","                'userID': list(train_data.user_id),\n","                'rating': list(train_data.user_rating)}\n","df = pd.DataFrame(ratings_dict)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h06AOUvdEmxX"},"source":["# A reader is still needed but only the rating_scale param is required.\n","# The Reader class is used to parse a file containing ratings.\n","reader = Reader(rating_scale=(1, 10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUcEBHV8EmxY"},"source":["# The columns must correspond to user id, item id and ratings (in that order).\n","data_sur = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqOwxyh3Emxa"},"source":["from collections import defaultdict\n","\n","from surprise import SVD\n","\n","# see https://surprise.readthedocs.io/en/stable/FAQ.html\n","def get_top_n(predictions, n=10):\n","    '''Return the top-N recommendation for each user from a set of predictions.\n","\n","    Args:\n","        predictions(list of Prediction objects): The list of predictions, as\n","            returned by the test method of an algorithm.\n","        n(int): The number of recommendation to output for each user. Default\n","            is 10.\n","\n","    Returns:\n","    A dict where keys are user (raw) ids and values are lists of tuples:\n","        [(raw item id, rating estimation), ...] of size n.\n","    '''\n","\n","    # First map the predictions to each user.\n","    top_n = defaultdict(list)\n","    for uid, iid, true_r, est, _ in predictions:\n","        top_n[uid].append((iid, est))\n","\n","    # Then sort the predictions for each user and retrieve the k highest ones.\n","    for uid, user_ratings in top_n.items():\n","        user_ratings.sort(key=lambda x: x[1], reverse=True)\n","        top_n[uid] = user_ratings[:n]\n","\n","    return top_n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3ux6yy9Emxb"},"source":["# First train an SVD algorithm on the movielens dataset.\n","# data = Dataset.load_builtin('ml-100k')\n","trainset = data_sur.build_full_trainset()\n","algo = SVD()\n","algo.fit(trainset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wt2HLtZ3Emxc","scrolled":true},"source":["user = 18\n","train_data.groupby('user_id').get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oafl78X1Emxd","scrolled":true},"source":["dev_data.groupby('user_id').get_group(user)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fxiw0F22Emxe"},"source":["# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n","predictions = algo.test([(user, anime, 0) for anime in anime_to_idx])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvzEtu80Emxh","scrolled":true},"source":["top_k = 10\n","line_on_user_user(user, top_k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_MJECgiEmxi","scrolled":true},"source":["line_on_svd(user, top_k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nT8mwv0DEmxj","scrolled":true},"source":["top_n = get_top_n(predictions, n=top_k)\n","top_n[user]"],"execution_count":null,"outputs":[]}]}